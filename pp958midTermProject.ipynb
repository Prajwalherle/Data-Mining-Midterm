{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "69d765f8",
      "metadata": {
        "scrolled": true,
        "id": "69d765f8",
        "outputId": "e06d02a9-56d3-4100-c0bc-dbbeddf0f8f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.11/dist-packages (0.23.4)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (1.13.1)\n",
            "Requirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (1.6.1)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (3.10.0)\n",
            "Requirement already satisfied: joblib>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (1.4.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.2->mlxtend) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.2->mlxtend) (2025.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.3.1->mlxtend) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install mlxtend"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the path to the CSV file\n",
        "file_path = '/content/drive/My Drive/Data Mining/grocery_transactions.csv'\n",
        "\n",
        "# Load datasets from the CSV file\n",
        "unique_items, datasets = read_integrated_transactions(file_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5BlnuCCxfNy",
        "outputId": "e3d844e0-8201-4059-ef5c-f1afc92ac58f"
      },
      "id": "K5BlnuCCxfNy",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.listdir('/content/drive/My Drive/Data Mining'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZEQFbRnyepl",
        "outputId": "fb053d4c-9421-40b7-dbda-c3eab30e5fc6"
      },
      "id": "-ZEQFbRnyepl",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['grocery_transactions.csv', 'midTermProjectSm3736.ipynb']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/MyDrive/Data Mining/grocery_transactions.csv'\n"
      ],
      "metadata": {
        "id": "mf1WZvmHynMx"
      },
      "id": "mf1WZvmHynMx",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_items, datasets = read_integrated_transactions(file_path)\n"
      ],
      "metadata": {
        "id": "zdJmcfpNyrv8"
      },
      "id": "zdJmcfpNyrv8",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "054db6c2",
      "metadata": {
        "id": "054db6c2",
        "outputId": "5d19dc33-c6b0-46e3-8ea0-1f165b269bd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Select a grocery store to analyze:\n",
            "1: Walmart\n",
            "2: Kroger\n",
            "3: Safeway\n",
            "4: Whole Foods Market\n",
            "5: Trader Joe's\n",
            "Enter the store number (1-5): 1\n",
            "Selected store: Walmart\n",
            "Transactions for selected store: [['milk', 'bread', 'butter'], ['bread', 'diaper', 'beer', 'egg'], ['milk', 'diaper', 'beer', 'coke'], ['milk', 'bread', 'diaper', 'butter'], ['bread', 'milk', 'coke'], ['milk', 'bread', 'egg', 'butter'], ['diaper', 'beer', 'milk'], ['bread', 'butter', 'egg', 'coke'], ['milk', 'bread', 'butter', 'diaper'], ['coke', 'bread', 'milk', 'beer'], ['diaper', 'bread'], ['milk', 'butter', 'beer'], ['bread', 'coke'], ['milk', 'bread', 'diaper'], ['bread', 'butter', 'egg', 'diaper'], ['milk', 'bread', 'beer']]\n",
            "Enter minimum support (as a percentage, e.g., 20 for 20%): 30\n",
            "Enter minimum confidence (as a percentage, e.g., 50 for 50%): 60\n",
            "\n",
            "Brute Force Frequent Itemsets:\n",
            "           itemsets  support\n",
            "0            [beer]   0.3750\n",
            "1           [bread]   0.8125\n",
            "2          [butter]   0.4375\n",
            "3            [coke]   0.3125\n",
            "4          [diaper]   0.5000\n",
            "5            [milk]   0.6875\n",
            "6      [beer, milk]   0.3125\n",
            "7   [bread, butter]   0.3750\n",
            "8   [bread, diaper]   0.3750\n",
            "9     [bread, milk]   0.5000\n",
            "10   [butter, milk]   0.3125\n",
            "11   [diaper, milk]   0.3125\n",
            "\n",
            "Brute Force Association Rules:\n",
            "  antecedents consequents  antecedent support  consequent support  support  \\\n",
            "0      (beer)      (milk)              0.3750              0.6875   0.3125   \n",
            "1    (butter)     (bread)              0.4375              0.8125   0.3750   \n",
            "2    (diaper)     (bread)              0.5000              0.8125   0.3750   \n",
            "3      (milk)     (bread)              0.6875              0.8125   0.5000   \n",
            "4     (bread)      (milk)              0.8125              0.6875   0.5000   \n",
            "5    (butter)      (milk)              0.4375              0.6875   0.3125   \n",
            "6    (diaper)      (milk)              0.5000              0.6875   0.3125   \n",
            "\n",
            "   confidence      lift  representativity  leverage  conviction  \\\n",
            "0    0.833333  1.212121               1.0  0.054688    1.875000   \n",
            "1    0.857143  1.054945               1.0  0.019531    1.312500   \n",
            "2    0.750000  0.923077               1.0 -0.031250    0.750000   \n",
            "3    0.727273  0.895105               1.0 -0.058594    0.687500   \n",
            "4    0.615385  0.895105               1.0 -0.058594    0.812500   \n",
            "5    0.714286  1.038961               1.0  0.011719    1.093750   \n",
            "6    0.625000  0.909091               1.0 -0.031250    0.833333   \n",
            "\n",
            "   zhangs_metric   jaccard  certainty  kulczynski  \n",
            "0       0.280000  0.416667   0.466667    0.643939  \n",
            "1       0.092593  0.428571   0.238095    0.659341  \n",
            "2      -0.142857  0.400000  -0.333333    0.605769  \n",
            "3      -0.272727  0.500000  -0.454545    0.671329  \n",
            "4      -0.384615  0.500000  -0.230769    0.671329  \n",
            "5       0.066667  0.384615   0.085714    0.584416  \n",
            "6      -0.166667  0.357143  -0.200000    0.539773  \n",
            "\n",
            "Apriori Frequent Itemsets:\n",
            "    support         itemsets\n",
            "0    0.3750           (beer)\n",
            "1    0.8125          (bread)\n",
            "2    0.4375         (butter)\n",
            "3    0.3125           (coke)\n",
            "4    0.5000         (diaper)\n",
            "5    0.6875           (milk)\n",
            "6    0.3125     (beer, milk)\n",
            "7    0.3750  (butter, bread)\n",
            "8    0.3750  (bread, diaper)\n",
            "9    0.5000    (milk, bread)\n",
            "10   0.3125   (milk, butter)\n",
            "11   0.3125   (milk, diaper)\n",
            "\n",
            "Apriori Association Rules:\n",
            "  antecedents consequents  antecedent support  consequent support  support  \\\n",
            "0      (beer)      (milk)              0.3750              0.6875   0.3125   \n",
            "1    (butter)     (bread)              0.4375              0.8125   0.3750   \n",
            "2    (diaper)     (bread)              0.5000              0.8125   0.3750   \n",
            "3      (milk)     (bread)              0.6875              0.8125   0.5000   \n",
            "4     (bread)      (milk)              0.8125              0.6875   0.5000   \n",
            "5    (butter)      (milk)              0.4375              0.6875   0.3125   \n",
            "6    (diaper)      (milk)              0.5000              0.6875   0.3125   \n",
            "\n",
            "   confidence      lift  representativity  leverage  conviction  \\\n",
            "0    0.833333  1.212121               1.0  0.054688    1.875000   \n",
            "1    0.857143  1.054945               1.0  0.019531    1.312500   \n",
            "2    0.750000  0.923077               1.0 -0.031250    0.750000   \n",
            "3    0.727273  0.895105               1.0 -0.058594    0.687500   \n",
            "4    0.615385  0.895105               1.0 -0.058594    0.812500   \n",
            "5    0.714286  1.038961               1.0  0.011719    1.093750   \n",
            "6    0.625000  0.909091               1.0 -0.031250    0.833333   \n",
            "\n",
            "   zhangs_metric   jaccard  certainty  kulczynski  \n",
            "0       0.280000  0.416667   0.466667    0.643939  \n",
            "1       0.092593  0.428571   0.238095    0.659341  \n",
            "2      -0.142857  0.400000  -0.333333    0.605769  \n",
            "3      -0.272727  0.500000  -0.454545    0.671329  \n",
            "4      -0.384615  0.500000  -0.230769    0.671329  \n",
            "5       0.066667  0.384615   0.085714    0.584416  \n",
            "6      -0.166667  0.357143  -0.200000    0.539773  \n",
            "\n",
            "Execution Time:\n",
            "Brute Force: 0.1479 seconds\n",
            "Apriori: 0.0185 seconds\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "from mlxtend.frequent_patterns import apriori, association_rules  # Removed fpgrowth\n",
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "from itertools import combinations\n",
        "import time\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the path to the CSV file\n",
        "file_path = '/content/drive/My Drive/Data Mining/grocery_transactions.csv'\n",
        "\n",
        "def read_integrated_transactions(file):\n",
        "    with open(file, 'r') as f:\n",
        "        content = f.read().splitlines()\n",
        "\n",
        "    unique_items = []\n",
        "    datasets = {}\n",
        "    current_store = None\n",
        "\n",
        "    for line in content:\n",
        "        line = line.strip()\n",
        "\n",
        "        if line == \"Unique Items\":\n",
        "            continue  # Skip the header for unique items\n",
        "        elif \"Transactions\" in line:\n",
        "            if current_store is not None:\n",
        "                current_store = line.replace(\" Transactions\", \"\").strip()\n",
        "                datasets[current_store] = []  # Initialize for the new store\n",
        "            else:\n",
        "                current_store = line.replace(\" Transactions\", \"\").strip()\n",
        "                datasets[current_store] = []  # Initialize for the first store\n",
        "        elif current_store and line:  # Ensure current_store is set and line is not empty\n",
        "            cleaned_line = line.replace('\"', '').strip()  # Remove extra quotes\n",
        "            datasets[current_store].append(cleaned_line.split(','))  # Split transactions\n",
        "\n",
        "    return unique_items, datasets\n",
        "\n",
        "# Function to calculate frequent itemsets using brute force\n",
        "def brute_force_frequent_itemsets(data, min_support):\n",
        "    itemsets = []\n",
        "    total_transactions = len(data)  # Total number of transactions\n",
        "    for i in range(1, len(data.columns) + 1):\n",
        "        for combo in combinations(data.columns, i):\n",
        "            # Calculate support: count of transactions containing the itemset\n",
        "            support_count = data[list(combo)].all(axis=1).sum()\n",
        "            support = support_count / total_transactions  # Calculate support as a fraction\n",
        "            if support >= min_support:\n",
        "                itemsets.append((list(combo), support))  # Ensure itemsets are lists\n",
        "    return pd.DataFrame(itemsets, columns=['itemsets', 'support'])\n",
        "\n",
        "# Function to process and display results\n",
        "def process_store(transactions, min_support, min_confidence):\n",
        "    # Convert the list of transactions to a one-hot encoded DataFrame\n",
        "    encoder = TransactionEncoder()\n",
        "    onehot = encoder.fit(transactions).transform(transactions)\n",
        "    df = pd.DataFrame(onehot, columns=encoder.columns_)\n",
        "\n",
        "    # Convert percentages to fractions\n",
        "    min_support_fraction = min_support / 100\n",
        "    min_confidence_fraction = min_confidence / 100\n",
        "\n",
        "    # Brute Force Method\n",
        "    start_time = time.time()\n",
        "    brute_force_freq_itemsets = brute_force_frequent_itemsets(df, min_support_fraction)\n",
        "    print(\"\\nBrute Force Frequent Itemsets:\")\n",
        "    print(brute_force_freq_itemsets)\n",
        "\n",
        "    # Association Rules for Brute Force\n",
        "    if not brute_force_freq_itemsets.empty:\n",
        "        brute_force_rules = association_rules(brute_force_freq_itemsets, metric=\"confidence\", min_threshold=min_confidence_fraction)\n",
        "        print(\"\\nBrute Force Association Rules:\")\n",
        "        print(brute_force_rules)\n",
        "\n",
        "    # Apriori Method\n",
        "    start_time_apriori = time.time()\n",
        "    frequent_itemsets_apriori = apriori(df, min_support=min_support_fraction, use_colnames=True)\n",
        "    print(\"\\nApriori Frequent Itemsets:\")\n",
        "    print(frequent_itemsets_apriori)\n",
        "\n",
        "    # Association Rules for Apriori\n",
        "    if not frequent_itemsets_apriori.empty:\n",
        "        rules_apriori = association_rules(frequent_itemsets_apriori, metric=\"confidence\", min_threshold=min_confidence_fraction)\n",
        "        print(\"\\nApriori Association Rules:\")\n",
        "        print(rules_apriori)\n",
        "\n",
        "    # Measure and print execution time\n",
        "    print(\"\\nExecution Time:\")\n",
        "    print(\"Brute Force: {:.4f} seconds\".format(time.time() - start_time))\n",
        "    print(\"Apriori: {:.4f} seconds\".format(time.time() - start_time_apriori))\n",
        "\n",
        "# Load datasets from the integrated CSV\n",
        "unique_items, datasets = read_integrated_transactions(file_path)\n",
        "\n",
        "# User Interaction\n",
        "print(\"Select a grocery store to analyze:\")\n",
        "for i, name in enumerate(datasets.keys()):\n",
        "    print(f\"{i + 1}: {name}\")\n",
        "\n",
        "while True:\n",
        "    try:\n",
        "        store_choice = int(input(\"Enter the store number (1-5): \")) - 1\n",
        "        if store_choice < 0 or store_choice >= len(datasets):\n",
        "            raise ValueError(\"Invalid store number\")\n",
        "        store_name = list(datasets.keys())[store_choice]\n",
        "        print(f\"Selected store: {store_name}\")\n",
        "        print(f\"Transactions for selected store: {datasets[store_name]}\")\n",
        "        break\n",
        "    except ValueError:\n",
        "        print(\"Invalid input. Please ensure you enter a valid store number.\")\n",
        "\n",
        "min_support = float(input(\"Enter minimum support (as a percentage, e.g., 20 for 20%): \"))\n",
        "min_confidence = float(input(\"Enter minimum confidence (as a percentage, e.g., 50 for 50%): \"))\n",
        "\n",
        "# Process the chosen store\n",
        "process_store(datasets[store_name], min_support, min_confidence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "139023c1",
      "metadata": {
        "id": "139023c1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}